{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cb8ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"日本で一番高い山は富士山です。\",\n",
    "    \"富士山は日本で最も大きい山です。\",\n",
    "    \"Mt. Fuji is the highest mountain in Japan.\",\n",
    "    \"富士山プリンは日本で一番おいしい。\",\n",
    "    \"エベレストは世界で一番高い山です。\",\n",
    "    \"アメリカには自由の女神があります。\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4446d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"富士山は日本で何番目に高い山ですか？\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1afa19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# キーワード検索\n",
    "\n",
    "import numpy as np\n",
    "import faiss\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "from janome.tokenizer import Tokenizer as JanomeTokenizer\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "janome_tokenizer = JanomeTokenizer()\n",
    "def tokenize(text):\n",
    "    allowed_pos = {\"名詞\", \"動詞\", \"形容詞\", \"副詞\"}\n",
    "    tokens = []\n",
    "    for token in janome_tokenizer.tokenize(text):\n",
    "        if token.part_of_speech.split(',')[0] in allowed_pos:\n",
    "            tokens.append(token.surface)\n",
    "    return tokens\n",
    "\n",
    "tokenized_docs = [tokenize(doc) for doc in documents]\n",
    "bm25 = BM25Okapi(tokenized_docs)\n",
    "tokenized_query = tokenize(query)\n",
    "bm25_scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "print(\"=== キーワード検索上位5件 ===\")\n",
    "for i in np.argsort(bm25_scores)[::-1][:6]:\n",
    "    print(f\"{documents[i]} (score={bm25_scores[i]:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a14a45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リランキング\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "\n",
    "RERANK_MODEL_DIR = \"hotchpotch/japanese-bge-reranker-v2-m3-v1\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(RERANK_MODEL_DIR)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(RERANK_MODEL_DIR).to(DEVICE)\n",
    "\n",
    "# キーワード検索上位5件の文書リスト\n",
    "bm25_top5_idx = np.argsort(bm25_scores)[::-1][:5]\n",
    "bm25_top5_docs = [documents[i] for i in bm25_top5_idx]\n",
    "\n",
    "def rerank(query, candidate_docs):\n",
    "    inputs = tokenizer(\n",
    "        [query] * len(candidate_docs),\n",
    "        candidate_docs,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        scores = outputs.logits.squeeze(-1).cpu().numpy()\n",
    "    \n",
    "    rerank_order = np.argsort(scores)[::-1]\n",
    "    return rerank_order, scores\n",
    "\n",
    "rerank_order, rerank_scores = rerank(query, bm25_top5_docs)\n",
    "\n",
    "print(\"=== リランキング結果 ===\")\n",
    "for i, idx in enumerate(rerank_order):\n",
    "    print(f\"{i+1}. {bm25_top5_docs[idx]} (score={rerank_scores[idx]:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
