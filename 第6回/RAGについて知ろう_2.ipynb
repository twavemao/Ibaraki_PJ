{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82239a09",
   "metadata": {},
   "source": [
    "### 第1セル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4d6230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 質問文\n",
    "query = \"富士山は日本で何番目に高い山ですか？\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f470aeb",
   "metadata": {},
   "source": [
    "### 第2セル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "181f14e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検索対象\n",
    "\n",
    "texts = [\n",
    "    \"日本で一番高い山は富士山です。\",\n",
    "    \"富士山は日本で最も大きい山です。\",\n",
    "    \"Mt. Fuji is the highest mountain in Japan.\",\n",
    "    \"富士山プリンは日本で一番おいしい。\",\n",
    "    \"エベレストは世界で一番高い山です。\",\n",
    "    \"アメリカには自由の女神があります。\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b269b4",
   "metadata": {},
   "source": [
    "### 第3セル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a63bcb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== キーワード検索上位5件 ===\n",
      "1:日本で一番高い山は富士山です。 (score=0.62)\n",
      "2:エベレストは世界で一番高い山です。 (score=0.62)\n",
      "3:富士山プリンは日本で一番おいしい。 (score=0.00)\n",
      "4:富士山は日本で最も大きい山です。 (score=0.00)\n",
      "5:アメリカには自由の女神があります。 (score=0.00)\n",
      "6:Mt. Fuji is the highest mountain in Japan. (score=0.00)\n",
      "\n",
      "=== ベクトル検索上位5件（類似度） ===\n",
      "1:日本で一番高い山は富士山です。 (similarity=0.9052)\n",
      "2:富士山は日本で最も大きい山です。 (similarity=0.9008)\n",
      "3:Mt. Fuji is the highest mountain in Japan. (similarity=0.8347)\n",
      "4:富士山プリンは日本で一番おいしい。 (similarity=0.7952)\n",
      "5:エベレストは世界で一番高い山です。 (similarity=0.7523)\n",
      "6:アメリカには自由の女神があります。 (similarity=0.6102)\n"
     ]
    }
   ],
   "source": [
    "# キーワード検索\n",
    "\n",
    "import numpy as np\n",
    "import faiss\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from janome.tokenizer import Tokenizer as JanomeTokenizer\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "#トークンに分ける\n",
    "janome_tokenizer = JanomeTokenizer()\n",
    "def tokenize(text):\n",
    "    allowed_pos = {\"名詞\", \"動詞\", \"形容詞\", \"副詞\"}\n",
    "    tokens = []\n",
    "    for token in janome_tokenizer.tokenize(text):\n",
    "        if token.part_of_speech.split(',')[0] in allowed_pos:\n",
    "            tokens.append(token.surface)\n",
    "    return tokens\n",
    "\n",
    "#トークンで分ける\n",
    "tokenized_docs = [tokenize(doc) for doc in texts]\n",
    "keyword_model = BM25Okapi(tokenized_docs)\n",
    "tokenized_query = tokenize(query)\n",
    "keyword_scores = keyword_model.get_scores(tokenized_query)\n",
    "\n",
    "# キーワード検索の順位付け\n",
    "keyword_ranked = sorted(zip(keyword_scores, texts), reverse=True)\n",
    "\n",
    "# print(\"クエリの形態素解析結果:\", tokenized_query)\n",
    "# print(\"テキストの形態素解析結果：\", tokenized_docs)\n",
    "\n",
    "# ベクトル検索\n",
    "\n",
    "MODEL_NAME = \"./bge-m3\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def encode(texts):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(DEVICE)\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        # mean_pooling + 即座正規化\n",
    "        token_embeddings = outputs.last_hidden_state\n",
    "        mask = inputs[\"attention_mask\"].unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        embeddings = torch.nn.functional.normalize(\n",
    "            (token_embeddings * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-9), \n",
    "            p=2, dim=1\n",
    "        )\n",
    "        \n",
    "        return embeddings.cpu().numpy()\n",
    "\n",
    "doc_embeddings = encode(texts)\n",
    "query_embedding = encode([query])\n",
    "\n",
    "# 既に正規化済みなのでそのまま使用\n",
    "index = faiss.IndexFlatIP(doc_embeddings.shape[1])\n",
    "index.add(doc_embeddings)\n",
    "similarities, indices = index.search(query_embedding, 6)\n",
    "\n",
    "print(\"=== キーワード検索上位5件 ===\")\n",
    "for rank, (score, doc) in enumerate(keyword_ranked[:6], 1):\n",
    "    print(f\"{rank}:{doc} (score={score:.2f})\")\n",
    "\n",
    "print(\"\\n=== ベクトル検索上位5件（類似度） ===\")\n",
    "for rank, idx in enumerate(indices[0]):\n",
    "    print(f\"{rank+1}:{texts[idx]} (similarity={similarities[0][rank]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a112bdc",
   "metadata": {},
   "source": [
    "### 第4セル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e508a9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== リランキング結果 ===\n",
      "1. 日本で一番高い山は富士山です。 (score=6.0030)\n",
      "2. Mt. Fuji is the highest mountain in Japan. (score=5.3655)\n",
      "3. 富士山は日本で最も大きい山です。 (score=2.2264)\n",
      "4. エベレストは世界で一番高い山です。 (score=-2.7905)\n",
      "5. 富士山プリンは日本で一番おいしい。 (score=-5.9260)\n",
      "6. アメリカには自由の女神があります。 (score=-10.6326)\n"
     ]
    }
   ],
   "source": [
    "# リランキング\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "\n",
    "RERANK_MODEL_DIR = \"./japanese-bge-reranker-v2-m3-v1\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(RERANK_MODEL_DIR)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(RERANK_MODEL_DIR).to(DEVICE)\n",
    "\n",
    "# キーワード検索文書リスト（スコアを除いてテキストのみ）\n",
    "keyword_docs_texts = [doc for score, doc in keyword_ranked]\n",
    "\n",
    "def rerank(query, candidate_docs):\n",
    "    inputs = tokenizer(\n",
    "        [query] * len(candidate_docs),\n",
    "        candidate_docs,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        scores = outputs.logits.squeeze(-1).cpu().numpy()\n",
    "    \n",
    "    rerank_order = np.argsort(scores)[::-1]\n",
    "    return rerank_order, scores\n",
    "\n",
    "rerank_order, rerank_scores = rerank(query, keyword_docs_texts)\n",
    "\n",
    "print(\"=== リランキング結果 ===\")\n",
    "for i, idx in enumerate(rerank_order):\n",
    "    print(f\"{i+1}. {keyword_docs_texts[idx]} (score={rerank_scores[idx]:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "education",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
